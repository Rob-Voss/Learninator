<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>REINFORCEjs: WallWorld demo</title>
    <meta name="description" content="Multi-agent comparison workbench">
    <meta name="author" content="Mr-Yellow">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/css/bootstrap-theme.min.css" rel="stylesheet" type="text/css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/css/bootstrap.min.css" rel="stylesheet" type="text/css">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="css/styles.css" rel="stylesheet" type="text/css">
    <link href="css/twitch-nav.css" rel="stylesheet" type="text/css">

    <style>
        #wrap {
            width: 800px;
            margin-left: auto;
            margin-right: auto;
        }

        h2 {
            text-align: center;
        }

        body {
            font-family: Arial, "Helvetica Neue", Helvetica, sans-serif;
        }

        canvas {
            border: 1px solid black;
        }
    </style>

    <script type="application/javascript">
        var canvas, ctx;

        // Draw everything
        function draw() {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.lineWidth = 1;
            var agents = w.agents;

            // draw walls in environment
            ctx.strokeStyle = "rgb(0,0,0)";
            ctx.beginPath();
            for (var i = 0, n = w.walls.length; i < n; i++) {
                var q = w.walls[i];
                ctx.moveTo(q.p1.x, q.p1.y);
                ctx.lineTo(q.p2.x, q.p2.y);
            }
            ctx.stroke();

            // draw agents
            var r = 0;

            for (var i = 0, n = agents.length; i < n; i++) {
                var a = agents[i];

                // consistently color agent based on config
                ctx.fillStyle = a.colour;
                ctx.strokeStyle = "rgb(0,0,0)";

                // draw agents body
                ctx.beginPath();
                ctx.arc(a.op.x, a.op.y, a.rad, 0, Math.PI * 2, true);
                ctx.fill();
                ctx.stroke();

                // draw agents sight
                for (ei = 0, ne = a.sensors.eyes.length; ei < ne; ei++) {
                    var eye = a.sensors.eyes[ei];
                    var er = eye.sensed_proximity;
                    if (eye.sensed_type === -1 || eye.sensed_type === 0) {
                        ctx.strokeStyle = "rgb(0,0,0)"; // wall or nothing
                    }
                    if (eye.sensed_type === 1) {
                        ctx.strokeStyle = "rgb(255,150,150)";
                    } // apples
                    if (eye.sensed_type === 2) {
                        ctx.strokeStyle = "rgb(150,255,150)";
                    } // poison
                    ctx.beginPath();
                    ctx.moveTo(a.op.x, a.op.y);
                    ctx.lineTo(a.op.x + er * Math.sin(a.oangle + eye.angle),
                            a.op.y + er * Math.cos(a.oangle + eye.angle));
                    ctx.stroke();
                }

                // draw goal
                var g = a.goal;
                if (g) {
                    ctx.fillStyle = "rgb(150, 150, 150)";
                    ctx.strokeStyle = "rgb(150,150,150)";
                    if (g.type === 1) ctx.fillStyle = "rgb(255, 150, 150)";
                    if (g.type === 2) ctx.fillStyle = "rgb(150, 255, 150)";
                    ctx.beginPath();
                    ctx.arc(g.p.x, g.p.y, g.rad, 0, Math.PI * 2, true);
                    ctx.fill();
                    ctx.stroke();
                }

                // draw agents smell
                for (ei = 0, ne = a.sensors.nostrils.length; ei < ne; ei++) {
                    var nostril = a.sensors.nostrils[ei];
                    var nr = nostril.sensed_proximity;
                    if (nostril.sensed_type === -1) {
                        ctx.strokeStyle = "rgb(230,230,230)";
                    } else if (nostril.sensed_type === 0) {
                        ctx.strokeStyle = "rgb(255,150,150)";
                    }
                    ctx.beginPath();
                    ctx.moveTo(a.op.x, a.op.y);
                    ctx.lineTo(a.op.x + nr * Math.sin(a.oangle + nostril.angle),
                            a.op.y + nr * Math.cos(a.oangle + nostril.angle));
                    ctx.stroke();
                }
            }

            // draw items
            ctx.strokeStyle = "rgb(0,0,0)";
            for (var i = 0, n = w.items.length; i < n; i++) {
                var it = w.items[i];
                if (it.type === 1) ctx.fillStyle = "rgb(255, 150, 150)";
                if (it.type === 2) ctx.fillStyle = "rgb(150, 255, 150)";
                ctx.beginPath();
                ctx.arc(it.p.x, it.p.y, it.rad, 0, Math.PI * 2, true);
                ctx.fill();
                ctx.stroke();
            }
        }

        // Tick the world
        function tick() {

            if (simspeed === 3) {
                for (var k = 0; k < 50; k++) {
                    w.tick();
                }
            } else {
                w.tick();
            }
            draw();

            for (var i = 0; i < w.agents.length; i++) {
                var agent = w.agents[i];

                var rew = agent.last_reward;
                if (agent.smooth_reward == null) {
                    agent.smooth_reward = rew;
                }
                agent.smooth_reward = agent.smooth_reward * 0.999 + rew * 0.001;
                agent.flott += 1;
                if (agent.flott === 50) {
                    // record smooth reward
                    if (agent.smooth_reward_history.length >= nflot) {
                        agent.smooth_reward_history = agent.smooth_reward_history.slice(1);
                    }
                    agent.smooth_reward_history.push(agent.smooth_reward);
                    agent.flott = 0;
                }

                if (typeof agent.brain.expi !== 'undefined') {
                    $("#expi_" + agent.id).html(agent.brain.expi);
                }
                if (typeof agent.brain.tderror !== 'undefined') {
                    $("#tde_" + agent.id).html(agent.brain.tderror.toFixed(3));
                }
            }
        }

        // flot stuff
        var nflot = 2000;
        function initFlot() {
            var container = $("#flotreward");
            var series = new Array(w.agents.length);
            for (var i = 0; i < w.agents.length; i++) {
                var a = w.agents[i];
                series[i] = {
                    color: a.colour,
                    data: getFlotRewards(a),
                    lines: {
                        show: true,
                        fill: false
                    },
                    label: 'Agent ' + a.id
                };
            }

            var plot = $.plot(container, series, {
                grid: {
                    borderWidth: 1,
                    minBorderMargin: 20,
                    labelMargin: 10,
                    backgroundColor: {
                        colors: ["#FFF", "#e4f4f4"]
                    },
                    margin: {
                        top: 10,
                        bottom: 10,
                        left: 10,
                    }
                },
                xaxis: {
                    min: 0,
                    max: nflot
                },
                yaxis: {
                    min: 0,
                    max: 0.1
                }
            });
            setInterval(function () {
                for (var i = 0; i < w.agents.length; i++) {
                    series[i].data = getFlotRewards(w.agents[i]);
                }
                plot.setData(series);
                plot.draw();
            }, 100);
        }
        function getFlotRewards(agent) {
            // zip rewards into flot data
            var res = [];
            for (var i = 0, n = agent.smooth_reward_history.length; i < n; i++) {
                res.push([i, agent.smooth_reward_history[i]]);
            }
            return res;
        }

        var simspeed = 2;
        function goveryfast() {
            window.clearInterval(current_interval_id);
            current_interval_id = setInterval(tick, 0);
            skipdraw = true;
            simspeed = 3;
        }
        function gofast() {
            window.clearInterval(current_interval_id);
            current_interval_id = setInterval(tick, 0);
            skipdraw = true;
            simspeed = 2;
        }
        function gonormal() {
            window.clearInterval(current_interval_id);
            current_interval_id = setInterval(tick, 30);
            skipdraw = false;
            simspeed = 1;
        }
        function goslow() {
            window.clearInterval(current_interval_id);
            current_interval_id = setInterval(tick, 200);
            skipdraw = false;
            simspeed = 0;
        }

        /*
         function saveAgent(agent) {
         var brain = agent.brain;
         $("#mysterybox").fadeIn();
         $("#mysterybox").val(JSON.stringify(brain.toJSON()));
         }
         */

        function resetAgent(agent) {
            eval($("#agentspec_" + agent.id).val())
            var brain = new RL.DQNAgent(agent, spec);
            agent.brain = brain;
        }

        function resetAgents() {
            for (var i = 0; i < w.agents.length; i++) {
                resetAgent(w.agents[i]);
            }
        }

        /*
         function loadAgent() {
         $.getJSON( "agentzoo/wateragent.json", function( data ) {
         var agent = w.agents[0].brain;
         agent.fromJSON(data); // corss your fingers...
         // set epsilon to be much lower for more optimal behavior
         agent.epsilon = 0.05;
         $("#slider").slider('value', agent.epsilon);
         $("#eps").html(agent.epsilon.toFixed(2));
         // kill learning rate to not learn
         agent.alpha = 0;
         });
         }
         */

        function initAgent(id) {
            eval($("#agentspec_" + id).val());
            var a = new Agent(id, config);
            a.brain = new DQNAgent(a, spec); // give agent a TD brain
            //a.brain = new RL.RecurrentReinforceAgent(env, {});

            var goalx = randf(20, w.W - 20);
            var goaly = randf(20, w.H - 20);
            var goal = new Item(goalx, goaly, 0);
            goal.rad = 10;
            a.goal = goal;

            w.agents.push(a);

            $("#slider_" + id).slider({
                min: 0,
                max: 1,
                value: a.brain.epsilon,
                step: 0.01,
                slide: function (event, ui) {
                    a.brain.epsilon = ui.value;
                    $("#eps_" + id).html(ui.value.toFixed(2));
                }
            });
            $("#eps_" + id).html(a.brain.epsilon.toFixed(2));
            $("#slider_" + id).slider('value', a.brain.epsilon);
        }

        var w; // global world object
        var current_interval_id;
        var skipdraw = false;
        function start() {
            canvas = document.getElementById("canvas");
            ctx = canvas.getContext("2d");

            // Start small.
            w = new World(200, 200 * (canvas.height / canvas.width));
            w.agents = [];

            initAgent('01');
            initAgent('02');

            initFlot();
            gonormal();

            // render markdown
            $(".md").each(function () {
                $(this).html(marked($(this).html()));
            });
            renderJax();
        }

        // inner walls
        function walls() {
            if (w.W === canvas.width && w.H === canvas.height) {
                util_add_box(w.walls, 100, 100, 200, 300);
                w.walls.pop();
                util_add_box(w.walls, 400, 100, 200, 300);
                w.walls.pop();
            } else {
                util_add_box(w.walls, w.W / 3, w.H / 2, w.W / 3, 0);
            }
        }

        function sizeroom(larger) {
            if (larger) {
                w.W += w.W * 0.1;
                w.H += w.H * 0.1;
            } else {
                w.W -= w.W * 0.1;
                w.H -= w.H * 0.1;
            }
            w.W = Math.min(canvas.width, w.W);
            w.H = Math.min(canvas.height, w.H);
            w.walls = [];
            var pad = 0;
            util_add_box(w.walls, pad, pad, w.W - pad * 2, w.H - pad * 2);
        }

        var jaxrendered = false;
        function renderJax() {
            if (jaxrendered) {
                return;
            }
            (function () {
                var script = document.createElement("script");
                script.type = "text/javascript";
                script.src = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
                document.getElementsByTagName("head")[0].appendChild(script);
                jaxrendered = true;
            })();
        }

    </script>
    <style type="text/css">
        canvas {
            border: 1px solid white;
        }
    </style>

</head>
<body onload="start();">

<a href="https://github.com/karpathy/reinforcejs"><img style="position: absolute; top: 0; right: 0; border: 0;"
                                                       src="https://camo.githubusercontent.com/38ef81f8aca64bb9a64448d0d70f1308ef5341ab/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6461726b626c75655f3132313632312e706e67"
                                                       alt="Fork me on GitHub"
                                                       data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png"></a>

<div id="wrap">


    <div id="mynav" style="border-bottom:1px solid #999; padding-bottom: 10px; margin-bottom:50px;">
        <div>
            <img src="loop.svg" style="width:50px;height:50px;float:left;">

            <h1 style="font-size:50px;">REINFORCE<span style="color:#058;">js</span></h1>
        </div>
        <ul class="nav nav-pills">
            <li role="presentation"><a href="index.html">About</a></li>
            <li role="presentation"><a href="gridworld_dp.html">GridWorld: DP</a></li>
            <li role="presentation"><a href="gridworld_td.html">GridWorld: TD</a></li>
            <li role="presentation"><a href="puckworld.html">PuckWorld: DQN</a></li>
            <li role="presentation"><a href="waterworld.html">WaterWorld: DQN</a></li>
            <li role="presentation" class="active"><a href="wallworld.html">WallWorld: DQN</a></li>
        </ul>
    </div>

    <div class="form-inline">
        <div class="form-group">
            <label for="agentspec_01">Agent 01</label>
    <textarea id="agentspec_01" style="display: block;" class="form-control" rows="10" cols="44">
// agent sensor configuration
var nostril_num   = 31;
var nostril_names = [];
for (var i=1; i<=nostril_num; i++) {
  nostril_names.push('nostril_'+i);
}
var config = {
  colour: 'rgb(237,194,64)',
  sensors: {
    eyes: {
      names: ['range_4r','range_3l','range_2l','range_1l','range_1r','range_2r','range_3r','range_4r'],
      fov: 15*Math.PI/180,
      range: 85,
      types: 1
    },
    nostrils: {
      names: nostril_names,
      fov: 2*Math.PI/nostril_num,
      range: 750,
      types: 1
    }
  },
  actions: [
    [1.0,1.0],
    [1.0,0.75],
    [0.75,1.0],
    [0.5,0.0],
    [0.0,0.5]
  ]
};

// agent parameter spec to play with (this gets eval()'d on Agent reset)
var spec = {}
spec.update = 'qlearn'; // qlearn | sarsa
spec.gamma = 0.9; // discount factor, [0, 1)
spec.epsilon = 0.2; // initial epsilon for epsilon-greedy policy, [0, 1)
spec.alpha = 0.005; // value function learning rate
spec.experience_add_every = 1; // number of time steps before we add another experience to replay memory
spec.experience_size = 20000; // size of experience
spec.learning_steps_per_iteration = 32;
spec.tderror_clamp = 1.0; // for robustness
spec.num_hidden_units = 100 // number of neurons in hidden layer
    </textarea>
            <span class="help-block"><code>spec.update = 'qlearn'</code></span>
        </div>
        <div class="form-group">
            <label for="agentspec_02">Agent 02</label>
    <textarea id="agentspec_02" style="display: block;" class="form-control" rows="10" cols="44">
// agent sensor configuration
var nostril_num   = 31;
var nostril_names = [];
for (var i=1; i<=nostril_num; i++) {
  nostril_names.push('nostril_'+i);
}
var config = {
  colour: 'rgb(175,216,248)',
  sensors: {
    eyes: {
      names: ['range_4r','range_3l','range_2l','range_1l','range_1r','range_2r','range_3r','range_4r'],
      fov: 15*Math.PI/180,
      range: 85,
      types: 1
    },
    nostrils: {
      names: nostril_names,
      fov: 2*Math.PI/nostril_num,
      range: 750,
      types: 1
    }
  },
  actions: [
    [1.0,1.0],
    [1.0,0.75],
    [0.75,1.0],
    [0.5,0.0],
    [0.0,0.5]
  ]
};

// agent parameter spec to play with (this gets eval()'d on Agent reset)
var spec = {}
spec.update = 'sarsa'; // qlearn | sarsa
spec.gamma = 0.9; // discount factor, [0, 1)
spec.epsilon = 0.2; // initial epsilon for epsilon-greedy policy, [0, 1)
spec.alpha = 0.005; // value function learning rate
spec.experience_add_every = 1; // number of time steps before we add another experience to replay memory
spec.experience_size = 20000; // size of experience
spec.learning_steps_per_iteration = 32;
spec.tderror_clamp = 1.0; // for robustness
spec.num_hidden_units = 100 // number of neurons in hidden layer
    </textarea>
            <span class="help-block"><code>spec.update = 'sarsa'</code></span>
        </div>
    </div>

    <div style="text-align:center;">
        <button class="btn btn-danger" onclick="resetAgents()" style="width:150px;height:50px;margin-bottom:5px;">Reinit
            agents
        </button>
        <button class="btn btn-success" onclick="goveryfast()" style="width:150px;height:50px;margin-bottom:5px;">Go
            very fast
        </button>
        <button class="btn btn-success" onclick="gofast()" style="width:150px;height:50px;margin-bottom:5px;">Go fast
        </button>
        <button class="btn btn-success" onclick="gonormal()" style="width:150px;height:50px;margin-bottom:5px;">Go
            normal
        </button>
        <button class="btn btn-success" onclick="goslow()" style="width:150px;height:50px;margin-bottom:5px;">Go slow
        </button>

        <button class="btn btn-success" onclick="sizeroom(true)" style="width:150px;height:50px;margin-bottom:5px;">
            Larger
        </button>
        <button class="btn btn-success" onclick="sizeroom()" style="width:150px;height:50px;margin-bottom:5px;">
            Smaller
        </button>
        <button class="btn btn-success" onclick="walls()" style="width:150px;height:50px;margin-bottom:5px;">Inner
            walls
        </button>


        <canvas id="canvas" width="700" height="500"></canvas>
    </div>

    <div>
        Exploration epsilon:<br/>
        <span id="eps_01">0.15</span>

        <div id="slider_01"></div>
        <span id="eps_02">0.15</span>

        <div id="slider_02"></div>
    </div>

    <div class="row">
        <div class="col-md-6">
            Experience write pointer:<br/>
            <dl class="dl-horizontal">
                <dt>Agent 01</dt>
                <dd id="expi_01"></dd>
                <dt>Agent 02</dt>
                <dd id="expi_02"></dd>
            </dl>
        </div>
        <div class="col-md-6">
            Latest TD error:<br/>
            <dl class="dl-horizontal">
                <dt>Agent 01</dt>
                <dd id="tde_01"></dd>
                <dt>Agent 02</dt>
                <dd id="tde_02"></dd>
            </dl>
        </div>
    </div>

    <div id="flotreward" style="width:800px; height: 400px;"></div>

    <textarea id="mysterybox" style="width:100%;display:none;">mystery text box</textarea>

    <div id="exp" class="md">

### Setup

This is another Deep Q Learning demo with a more realistic and larger setup:

- The **state space** is continuous: The agent has 8 eye sensors each observes 1 variable: the range of
walls/items. Along with 31 nostril sensors each observes 1 variable: the range of goals (ignoring walls). This
is a total of 39-dimensional state space.
- There are 5 **actions** available to the agent: To turn on the spot (left or right), forward turns (left or
right), or straight forward.
- The **reward** awarded to the agent is +1 for making contact with their goal.

### TODO

* [ ] The agent's proprioception includes two additional sensors for its own speed ~~in both x and y
directions~~ on each wheel.

    </div>

    <br><br><br><br>
</div>

<script src="https://code.jquery.com/jquery-2.1.4.min.js"></script>
<script src="https://code.jquery.com/ui/1.11.4/jquery-ui.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.5/js/bootstrap.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.8.3/underscore-min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/flot/0.8.3/jquery.flot.js"></script>

<!-- markdown -->
<script type="text/javascript" src="js/lib/external/marked.js"></script>
<script type="text/javascript" src="js/lib/external/highlight.pack.js"></script>
<link rel="stylesheet" href="css/highlight_default.css">
<script>hljs.initHighlightingOnLoad();</script>

<script src="js/lib/Utility.js"></script>
<script type="text/javascript" src="js/lib/external/rl.js"></script>

<!-- environment dynamics -->
<script src="js/environments/WallWorld.js"></script>

</body>
</html>
